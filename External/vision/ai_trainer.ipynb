{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Trainer\n",
    "## 1. Introduction\n",
    "This is a Jupyter Notebook for training the AI that is used for this project. It is meant as a tool for training the AI with a prepared dataset and to showcase in detail how this works.\n",
    "\n",
    "## 2. Table of Contents\n",
    "1. [Introduction](#1-introduction)\n",
    "2. [Table of Contents](#2-table-of-contents)\n",
    "3. [Imports](#3-imports)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Imports\n",
    "The following libraries are imported:\n",
    "- `tensorflow`: a library contains tools for creating an AI model, imported as `tf`.\n",
    "- `keras`: a framework in `tensorflow` for defining the AI model from a list of layers.\n",
    "- `numpy`: a library that helps with handling lists of numbers in an efficient manner, import as `np`.\n",
    "- `cv2`: a library of highly optimized algorithms for computer vision.\n",
    "- `matplotlib.pyplot`: a library for plotting data, imported as `plt`.\n",
    "- `pathlib`: a library for handling filesystem paths.\n",
    "- `PIL`: a library for image processing.\n",
    "- `datetime`: a standard python library for dates and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import PIL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a Dataset\n",
    "This project uses a dataset of 256x256 grayscale images. There are three sub-directories in the dataset, one for each of the states **attacking**, **idling** and **walking** with the same name.\n",
    "\n",
    "```\n",
    "├── kajt_training_data/\n",
    "│   ├── attacking/\n",
    "│   ├── idling/\n",
    "│   ├── walking/\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Defining Dataset Parameters\n",
    "These are the parameters used for the dataset:\n",
    "- `batch_size`: The amount of images to use in each batch, every batch is used in all epochs.\n",
    "- `image_width`: The width of the *input* image.\n",
    "- `image_height`: The height of the *input* image.\n",
    "- `validation_split`: The percentage of the dataset to use as validation images to gauge accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_width = 256\n",
    "image_height = 256\n",
    "validation_split = 0.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Downloading the Dataset\n",
    "The images is stored as a `.tar.gz` file on OneDrive. The sharing URL OneDrive provides is not a direct download link, so it had to be converted to one, read more on [\"Generate OneDrive Direct-Download Link with C# or Python\"](https://towardsdatascience.com/how-to-get-onedrive-direct-download-link-ecb52a62fee4) by [Joe T. Santhanavanich](https://joets.medium.com/). The location of the dataset can be changed by altering the `dataset_url` variable, a local file can be used if `file:{file_path}` is used.\n",
    "\n",
    "Downloading and extracting the dataset from the URL is done by the `tf.keras.utils.get_file()` function, it provides a path to the downloaded dataset. The path is converted into a `pathlib.Path` object to make it easier to handle later on.\n",
    "\n",
    "> **NOTE**\n",
    "> \n",
    "> The dataset that is downloaded is cached, this means that the cached folder has to be deleted before a new dataset can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"\"\n",
    "data_directory = tf.keras.utils.get_file('kajt_training_data', origin=dataset_url, untar=True)\n",
    "data_directory = pathlib.Path(data_directory)\n",
    "\n",
    "# Print the amount of images in the dataset and how they are split\n",
    "print(f\"Image count: {len(list(data_directory.glob('*/*')))}\")\n",
    "print(f\"- attacking: {len(list(data_directory.glob('attacking/*')))}\")\n",
    "print(f\"- idling: {len(list(data_directory.glob('idling/*')))}\")\n",
    "print(f\"- walking: {len(list(data_directory.glob('walking/*')))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Previewing the Dataset\n",
    "These are some example images from the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1. Attacking States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(next(data_directory.glob('attacking/*')))\n",
    "PIL.Image.open(next(data_directory.glob('attacking/*')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. Idling States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(next(data_directory.glob('idling/*')))\n",
    "PIL.Image.open(next(data_directory.glob('idling/*')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3. Walking States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(next(data_directory.glob('walking/*')))\n",
    "PIL.Image.open(next(data_directory.glob('walking/*')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Loading the Dataset\n",
    "The dataset is loaded from the disk with `tf.keras.utils.image_dataset_from_directory()` function. Two datasets are created, one for training and one for validating. Validating is an essential part of the process of training the AI, it makes it significantly easier to identify if the model is overfitted. This is explained further in ????."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_directory,\n",
    "    validation_split=validation_split,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale')\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_directory,\n",
    "    validation_split=validation_split,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    image_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale')\n",
    "\n",
    "class_names = training_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Configure the Dataset for Performance\n",
    "The dataset is cached which means that the dataset is kept in memory and does not stop the model during training to load the data from the disk. Additionally, the dataset is prefetched which means that the next batch of data is loaded and processed while the model is training on the current batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = training_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the Model\n",
    "The `keras` framework greatly simplifies the process of creating the model with the help of the `Sequential` model. The `Sequential` model creates the AI model from a list of layers from the framework.\n",
    "\n",
    "A simple model is used in place of a Convolutional Neural Network for easy of implementation. While a CNN is the most common model to use for image classification, this project is constrained to a specific character and the image filters are trivial and thus the training time for a CNN to figure out optimal filters is a waste. Additionally, the character is locked in a known location and thus is not benefiting from spatial dependencies which is the main benefit of a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Adding the Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1. Rescaling\n",
    "The first layer is a `Rescaling` layer that converts the pixel data from a range of integer numbers between 0 and 255 to a range of floating point numbers between 0.0 and 1.0.\n",
    "\n",
    "This layer defines how the input should look like with `input_shape=(image_height, image_width, 1)`, this means a list the same length as the image is high contains lists of the same length as the image is wide that contains a list with a single element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Rescaling(1.0 / 255, input_shape=(image_height, image_width, 1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2. Flatten\n",
    "The second layer is a `Flatten` layer which reshapes the input from a multidimensional list of numbers into a one dimensional list of numbers. It turns the image, which is a list of lists of numbers into a single list of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Flatten())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3. Dense\n",
    "The next two layers are `Dense` layers, these are normal neural network layers, i.e. collections of neurons that applies a mathematical function on the input to produce an output.\n",
    "\n",
    "The `Dense` layers are passed an activation function, this is an additional function that each output is put through before being outputed. The `relu` (Rectified Linear Unit) function is the most common function and looks like this:\n",
    "\n",
    "$$ f(x) = x^+ = max(0, x) $$\n",
    "\n",
    "The first two `Dense` layers have 256 and 64 neurons respectively, these values are chosen completely arbitrarily and could likely be optimized by testing different configurations. But that is outside the scope of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3. Output Layer\n",
    "The last layer is the output layer and is also a `Dense` layer. The number of outputs is defined by the number of classes of images there are, which is three. The activation method for this layer is `softmax` instead of `relu`, this means that there is only a single output chosen and it is chosen by the largest output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "model.add(keras.layers.Dense(number_of_classes, activation='relu', name='outputs'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Compiling the Model\n",
    "The `optimizer` is the algorithm that, as the name would suggest, assists in optimizing the neural network. It does so by adjusting the properties of the neurons and the overall learning rate. The learning rate determines how large the adjustments the `loss` algorithm makes are. The Adam algorithm was chosen since it is the most common.\n",
    "\n",
    "A `loss` algorithm is responsible for adjusting the model so that it makes the correct classifcation.\n",
    "\n",
    "The `metrics=['accuracy']` argument means that the accuracy of the model is shown after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Model Summary\n",
    "How the model actually looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training the Model\n",
    "Train the model for 50 epochs, which means that the model trains on the dataset 10 times. The model is saved every epoch using the `keras.callbacks.ModelCheckpoint()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43/100 [===========>..................] - ETA: 21s - loss: 1.2164 - accuracy: 0.3212"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date_string = str(datetime.now()).replace(' ', '_').replace(':', '-')\n",
    "training_path = pathlib.Path('training', date_string)\n",
    "checkpoint_path = pathlib.Path(training_path, 'model.{epoch:02d}.hdf5')\n",
    "\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                           save_weights_only=False,\n",
    "                                                           save_best_only=False,\n",
    "                                                           verbose=1,\n",
    "                                                           save_freq='epoch')\n",
    "\n",
    "epochs = 50\n",
    "training_history = model.fit(training_dataset,\n",
    "                                  validation_data=validation_dataset,\n",
    "                                  epochs=epochs,\n",
    "                                  callbacks=[checkpoint_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing the Result\n",
    "Plot the `loss` and `accuracy` from the training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = training_history.history['accuracy']\n",
    "training_loss = training_history.history['loss']\n",
    "validation_accuracy = training_history.history['val_accuracy']\n",
    "validation_loss = training_history.history['val_loss']\n",
    "\n",
    "x_epochs = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_epochs, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(x_epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_epochs, training_loss, label='Training Loss')\n",
    "plt.plot(x_epochs, validation_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig(pathlib.Path('training', date_string, 'results-plot'))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Saving the Model Descriptor\n",
    "Saving the model descriptor as a JSON file helps with diffirentiating different models when multiple types have been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(pathlib.Path('training', date_string, 'descriptor.json'), \"w\") as json_file:\n",
    "    obj = json.loads(model.to_json())\n",
    "    \n",
    "    optimizer_config = optimizer.get_config()\n",
    "    if isinstance(optimizer_config['learning_rate'], np.floating):\n",
    "        optimizer_config['learning_rate'] = float(optimizer_config['learning_rate'])\n",
    "    obj['optimizer'] = optimizer_config\n",
    "    \n",
    "    obj['loss'] = loss.get_config()\n",
    "\n",
    "    json.dump(obj, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
